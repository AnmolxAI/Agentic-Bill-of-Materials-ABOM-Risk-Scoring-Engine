#!/usr/bin/env python3
"""
Test runner for ABOM Risk Scoring Engine
Tests all 5 test cases and validates expected results
"""

import requests
import json
import os
from pathlib import Path

BASE_URL = "http://localhost:8000"
TEST_DIR = Path(__file__).parent

# Expected results for each test case
# Note: Scaffolding modifiers can reduce scores by up to 30%
# FLOPs >= 1e25 automatically triggers Tier 4 override
# Tier thresholds per paper: Tier 0 (R=0), Tier 1 (0<R<5), Tier 2 (5â‰¤R<20), Tier 3 (20â‰¤R<50), Tier 4 (Râ‰¥50)
EXPECTED_RESULTS = {
    "test_case_1_minimal_risk.json": {
        "agency": 1,
        "autonomy": 1,
        "persistence": 0,
        "tier": 1,  # R = 1 Ã— 1 Ã— e^0 Ã— 0.85 = 0.85 â†’ Tier 1 (0 < R < 5)
        "score_range": (0, 5)
    },
    "test_case_2_low_risk.json": {
        "agency": 2,
        "autonomy": 2,
        "persistence": 1,
        "tier": 2,  # R = 2 Ã— 2 Ã— e^1 Ã— 0.765 â‰ˆ 8.32 â†’ Tier 2 (5 â‰¤ R < 20)
        "score_range": (5, 20)
    },
    "test_case_3_moderate_risk.json": {
        "agency": 4,
        "autonomy": 3,
        "persistence": 1,
        "tier": 3,  # R = 4 Ã— 3 Ã— e^1 Ã— 0.765 â‰ˆ 24.95 â†’ Tier 3 (20 â‰¤ R < 50)
        "score_range": (20, 50)
    },
    "test_case_4_high_risk.json": {
        "agency": 4,
        "autonomy": 3,
        "persistence": 2,
        "tier": 4,  # FLOPs (1.1e25) triggers Tier 4 override
        "score_range": (50, 100),  # R = 4 Ã— 3 Ã— e^2 Ã— 0.765 â‰ˆ 67.83
        "expect_tier_4_override": True
    },
    "test_case_5_critical_risk.json": {
        "agency": 4,
        "autonomy": 3,
        "persistence": 2,
        "tier": 4,  # FLOPs (2.0e25) triggers Tier 4 override
        "score_range": (50, 100),  # R = 4 Ã— 3 Ã— e^2 Ã— 0.9 â‰ˆ 79.8
        "expect_tier_4_override": True
    },
    "test_case_6_tier4_override.json": {
        "agency": 6,  # Critical capability (self-replication)
        "autonomy": 3,
        "persistence": 2,
        "tier": 4,  # FLOPs >= 1e25 AND capability flags trigger Tier 4
        "score_range": (100, 200),  # R = 6 Ã— 3 Ã— e^2 Ã— 1.0 â‰ˆ 133.0 (no scaffolding reduction)
        "expect_tier_4_override": True
    }
}

# Let me fix test_case_3 and test_case_5
# For tier 2 (25-50): A=4, U=3, P=1 gives 12Ã—e^1 â‰ˆ 32.6 âœ“
# For tier 4 (â‰¥100): We can't achieve this with max values, so let's adjust expectations
# Actually, let me recalculate test_case_3 to have P=1 instead of P=2


def run_test(test_file: str, expected: dict):
    """Run a single test case and validate results."""
    print(f"\n{'='*60}")
    print(f"Testing: {test_file}")
    print(f"{'='*60}")
    
    test_path = TEST_DIR / test_file
    
    if not test_path.exists():
        print(f"ERROR: Test file not found: {test_path}")
        return False
    
    try:
        # Read test file
        with open(test_path, 'r') as f:
            test_data = json.load(f)
        
        print(f"Test Input:")
        print(json.dumps(test_data, indent=2))
        
        # Send request to API
        with open(test_path, 'rb') as f:
            files = {'file': (test_file, f, 'application/json')}
            response = requests.post(f"{BASE_URL}/api/calculate-risk", files=files)
        
        if response.status_code != 200:
            print(f"ERROR: API returned status {response.status_code}")
            print(f"Response: {response.text}")
            return False
        
        result = response.json()
        
        print(f"\nActual Result:")
        print(json.dumps(result, indent=2))
        
        print(f"\nExpected:")
        print(f"  Agency: {expected['agency']}")
        print(f"  Autonomy: {expected['autonomy']}")
        print(f"  Persistence: {expected['persistence']}")
        print(f"  Tier: {expected['tier']}")
        print(f"  Score Range: {expected['score_range']}")
        
        # Validate results
        passed = True
        errors = []
        
        if result.get('agency') != expected['agency']:
            errors.append(f"Agency mismatch: expected {expected['agency']}, got {result.get('agency')}")
            passed = False
        
        if result.get('autonomy') != expected['autonomy']:
            errors.append(f"Autonomy mismatch: expected {expected['autonomy']}, got {result.get('autonomy')}")
            passed = False
        
        if result.get('persistence') != expected['persistence']:
            errors.append(f"Persistence mismatch: expected {expected['persistence']}, got {result.get('persistence')}")
            passed = False
        
        if result.get('tier') != expected['tier']:
            errors.append(f"Tier mismatch: expected {expected['tier']}, got {result.get('tier')}")
            passed = False
        
        score = result.get('score', 0)
        min_score, max_score = expected['score_range']
        if not (min_score <= score < max_score):
            errors.append(f"Score out of range: expected {min_score} â‰¤ score < {max_score}, got {score}")
            passed = False
        
        if errors:
            print(f"\nâŒ TEST FAILED")
            for error in errors:
                print(f"  - {error}")
        else:
            print(f"\nâœ… TEST PASSED")
        
        return passed
        
    except Exception as e:
        print(f"ERROR: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """Run all test cases."""
    print("ABOM Risk Scoring Engine - Test Suite")
    print("=" * 60)
    print(f"Testing against: {BASE_URL}")
    print(f"Test directory: {TEST_DIR}")
    
    # Check if server is running
    try:
        response = requests.get(f"{BASE_URL}/")
        if response.status_code != 200:
            print(f"\nERROR: Server not responding at {BASE_URL}")
            print("Please start the backend server first:")
            print("  cd backend && uvicorn main:app --reload --port 8000")
            return
    except requests.exceptions.ConnectionError:
        print(f"\nERROR: Cannot connect to server at {BASE_URL}")
        print("Please start the backend server first:")
        print("  cd backend && uvicorn main:app --reload --port 8000")
        return
    
    # Run all tests
    results = {}
    for test_file, expected in EXPECTED_RESULTS.items():
        results[test_file] = run_test(test_file, expected)
    
    # Summary
    print(f"\n{'='*60}")
    print("TEST SUMMARY")
    print(f"{'='*60}")
    
    passed = sum(1 for v in results.values() if v)
    total = len(results)
    
    for test_file, passed_test in results.items():
        status = "âœ… PASSED" if passed_test else "âŒ FAILED"
        print(f"{status}: {test_file}")
    
    print(f"\nTotal: {passed}/{total} tests passed")
    
    if passed == total:
        print("\nðŸŽ‰ All tests passed!")
        return 0
    else:
        print(f"\nâš ï¸  {total - passed} test(s) failed")
        return 1


if __name__ == "__main__":
    import sys
    sys.exit(main())

